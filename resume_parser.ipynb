{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f748e1-a5c0-484f-a3f0-319aec2aed12",
   "metadata": {},
   "source": [
    "## Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29362303-c941-4dda-8c82-17c28bc9867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import docx\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import re\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "import csv\n",
    "import ast\n",
    "import pandas as pd\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec4ce2b-90b9-46fc-88eb-9e216bb9ada6",
   "metadata": {},
   "source": [
    "## Define a function to extract the text from a resume of any compatibler format\n",
    "\n",
    "The `extract_text` function reads text from various file types (.pdf, .docx/.doc, image files, .txt) based on the file extension. It extracts text accordingly and returns it, printing a success message if extraction is completed or an error message if an exception occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0a4a91-4dfa-4bb5-8b35-8814899d9222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(file_path):\n",
    "    # Get the file extension in lowercase\n",
    "    file_extension = os.path.splitext(file_path)[1].lower()\n",
    "    \n",
    "    try:\n",
    "        print(f\"Extracting from : {file_path}\")\n",
    "        \n",
    "        if file_extension == '.pdf':\n",
    "            doc = fitz.open(file_path)\n",
    "            for page_num in range(doc.page_count):\n",
    "                page = doc.load_page(page_num)\n",
    "                text = page.get_text(\"text\") \n",
    "                print(\"\\tExtraction completed\")\n",
    "                return text\n",
    "                \n",
    "        elif file_extension in ['.docx', '.doc']:\n",
    "            doc = docx.Document(file_path)\n",
    "            print(\"\\tExtraction completed\")\n",
    "            return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "            \n",
    "        elif file_extension in ['.png', '.jpg', '.jpeg', '.tiff', '.bmp']:\n",
    "            image = Image.open(file_path)\n",
    "            print(\"\\tExtraction completed\")\n",
    "            return pytesseract.image_to_string(image)\n",
    "            \n",
    "        elif file_extension == '.txt':\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                print(\"\\tExtraction completed\")\n",
    "                return file.read()\n",
    "                \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        return \"\"  # Return empty string on error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0daa81c-e7bb-4906-b618-d7f690053f98",
   "metadata": {},
   "source": [
    "## Remove all special characters and retain relevant information\n",
    "\n",
    "This function, `clean_resume_text`, removes emails, special characters, and newlines from a resume's text, making it easier to process. It then adds any extracted emails back at the end of the cleaned text for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030db803-7a91-4579-89a6-919fd33655a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_resume_text(text):\n",
    "    # Regular expression for email addresses\n",
    "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "\n",
    "    # Regular expression for special characters (excluding spaces and alphanumeric characters)\n",
    "    special_characters = r'[^a-zA-Z0-9\\s]'\n",
    "    \n",
    "    # Find and extract emails\n",
    "    emails = re.findall(email_pattern, text)\n",
    "    \n",
    "    # Remove emails, phone numbers, and newline characters\n",
    "    cleaned_text = re.sub(email_pattern, '', text)\n",
    "    cleaned_text = cleaned_text.replace('\\n', ' ')  # Remove newlines by replacing them with spaces\n",
    "    \n",
    "    # Remove any remaining special characters\n",
    "    cleaned_text = re.sub(special_characters, ' ', cleaned_text)\n",
    "    \n",
    "    # Add extracted emails back at the end of the text\n",
    "    cleaned_text += \"\\n\" + \"\\n\".join(emails)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86905040-eda9-43f3-8d93-cd3bf6dc1723",
   "metadata": {},
   "source": [
    "## Extract relevant information from the resume in structured format\n",
    "\n",
    "The function, `extract_resume_info_from_text`, leverages the LangChain framework to extract structured data from a resume's raw text using the ChatGroq API, specifically tuned to capture and format keywords in a dictionary for ease of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "872a9c9b-999b-4c07-824f-c48978e503a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY'] = \"YOUR_API_KEY\" # Use your ChatGroq API key\n",
    "\n",
    "def extract_resume_info_from_text(preprocessed_text):\n",
    "    # Create the prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"I want you to go through a resume text and return the keywords for name ('name'), email ('email'), technical skills ('technical_skills'), soft skills ('soft_skills'), (give keywords based on the text), projects ('projects'), work experiences ('work_experience') (only the job role along with the company (Format: 'Job Role at Company' for each experience)) and total years of experience ('total_years_of_experience') of the person (only the total duration in 'm years n months' if more than a year else in 'n months'). Store the keywords only if present in the text. Let the extracted information be in dictionary format only.\"),\n",
    "            (\"user\", f\"Question: {preprocessed_text}\")\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Initialize the groqllm with the desired model (here Llama3.0) and temperature settings\n",
    "    groqllm = ChatGroq(model=\"llama3-70b-8192\",temperature=0) \n",
    "    \n",
    "    # Set up the output parser\n",
    "    outputparser = StrOutputParser()\n",
    "    \n",
    "    # Create a chain to process the input through the API and parse the output\n",
    "    chainSec = prompt | groqllm | outputparser\n",
    "    \n",
    "    # Run the chain with the preprocessed text\n",
    "    extracted_info = chainSec.invoke({'question': preprocessed_text})\n",
    "    \n",
    "    return extracted_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701160f-9d7a-4b15-8ac8-bd6e0f8db580",
   "metadata": {},
   "source": [
    "## Store the structured data in an Excel spreadsheet\n",
    "\n",
    "The `store_to_csv` function extracts a dictionary from a text, converts it, and appends it as a row to a specified CSV file. If the file doesn't exist, it writes headers based on dictionary keys before adding the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0dfc2d2-56ca-4e20-933b-fb8298363d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_to_csv(text_data, csv_filename):\n",
    "\n",
    "    # Extract the dictionary part from the text\n",
    "    start_idx = text_data.find(\"{\")\n",
    "    end_idx = text_data.rfind(\"}\") + 1\n",
    "    dict_text = text_data[start_idx:end_idx]\n",
    "    \n",
    "    # Convert to a dictionary\n",
    "    data = ast.literal_eval(dict_text)\n",
    "    \n",
    "    # Define the headers based on the dictionary keys\n",
    "    headers = data.keys()\n",
    "    \n",
    "    # Check if the CSV file already exists\n",
    "    file_exists = os.path.isfile(csv_filename)\n",
    "    \n",
    "    # Open the CSV file in append mode\n",
    "    with open(csv_filename, mode='a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=headers)\n",
    "        \n",
    "        # Write the header only if the file doesn't exist\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        \n",
    "        # Write the data row to the CSV file\n",
    "        writer.writerow(data)\n",
    "    \n",
    "    print(f\"Data stored successfully in {csv_filename}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be86c2-9d98-49fd-856c-4baa5c0d5435",
   "metadata": {},
   "source": [
    "## Working Example\n",
    "\n",
    "#### 1. `resume_text` stores the text extracted from the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8432f4a9-52b7-4d8c-a3fe-223d19fc7161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting from : sample_resumes/Sample Resume 4.pdf\n",
      "\tExtraction completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\n AashokKumar\\n aashokrekumar@gmail.com\\n +91-0176884977\\n Bangalore,India\\n https://www.linkedin.com/in/techaieashok\\n / h\\n https://github.com/loavespacetec Profile\\n Passionateaboutnewtechnologyhavingexperienceof2yearsinPython,DataScience,MachineLearning,SQL,\\n Cloud,etc.IhaveworkedonvariousprojectsindifferentdomainsofAIandMLfieldtosolvechallengingbusiness\\n problems.\\n ProfessionalExperience\\n Syste\\n m    Engineer\\n ,   TC  S  Oct2021–present\\n |  Bangalore,\\n India\\n •\\n Crastrategiestominimizerisksindecision-makingandenhanceprofitabilitythroughtheuseofdatascience\\n •\\n Workingwithinanagileenvironment,Ihaveeffectivelymanagedmultipletasksandprioritieswhilecollaborating\\n   withcross-functionalteamstodeliverprojectsontimeandtoahighstandard.Ihaveparticipatedindailystand-\\n upcallsandworkedwithinsprintcyclestoensurethetimelydeliveryofkeydeliverables.\\n •\\n Mystronganalyticalskills,combinedwithmyabilitytocommunicatecomplexfindingsinaclearandconcise\\n   manner,haveallowedmetoeffectivelycontributetodecision-makingprocessesanddrivepositivebusiness\\n   outcomes.Iamhighlymotivatedandtakeprideindeliveringhigh-qualityworkthatmeetstheneedsof\\n   stakeholdersandexceedsexpectations.\\n •\\n Performedexploratorydataanalysisforthecustomerdataaercleaningtherawdata,toderivemeaningful\\n   insightsandoutcomes.\\n •\\n Buildpredictivemodelsusingdifferentmachinelearningalgorithmstopredicttheprobabilityofcustomeron-\\n timeloanrepayment.IhavealsoutilizedTableautocreatecompellingvisualizationstosupportmyfindingsand\\n   insights.\\n •\\n Evaluatedtheaccuracyofthemodelsthroughtheuseofmetricssuchastheclassificationreport,confusion\\n   matrix,AUCscore,etc.\\n •\\n UtilizedvariousPythonlibrariesincludingNumPy,Pandas,Matplotlib,Seaborn,Scikit-learn,PySpark,andSciPy\\n   toeffectivelyperformdataanalysisandmodeling.\\n •\\n AppliedvarioustoolssuchasTableau,JupyterNotebook,TensorFlow,Anaconda,Git,Jira,Confluence,and\\n   Dockerindataanalysisandmodelingprocessestoincreaseefficiencyandeffectiveness.\\n Assistan\\n t   Syste\\n m    ,\\n Engineer   S\\n TC Mar2021–Sep2021\\n |  Bangalore,\\n India\\n •\\n Involvedintheanalysisoftestcases,writingoffeaturefilesusingtheGherkinlanguageabusinessdecipherable\\n   language,andimplementationusingC#forautomationtesting.\\n •\\n UsedUFTDeveloperforcapturingobjectsduringautomationtestinganddevelopment.\\n •\\n UtilizedvarioustoolssuchasVisualStudio,UFTDeveloper,Jira,Confluence,etctoperformautomation.\\n •\\n ReceivedtheLearningAchievementAwardinrecognitionofmydedicationandachievementsinprofessional\\n   \\ndevelopment. •\\n Successfullypassedtheinternalassessmentandreceivedadigitalprofile,leadingtoapromotiontotheposition\\n   \\nof System Engineer. PersonalProjects\\n Predictio\\n n    f  o   custome\\n r   eligibilit\\n y   fo  r    credi\\n t   usin\\n g    Machin\\n e    Learnin\\n g  •\\n WorkedwithalargedatasetofTaiwancustomerstopredictthelikelihoodofdefaultpaymentsandsupport\\n   informeddecision-making.\\n \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_text = extract_text(\"sample_resumes/Sample Resume 4.pdf\")\n",
    "resume_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a3a2dc-9fc1-4e0d-9e47-35f30ce90708",
   "metadata": {},
   "source": [
    "#### 2. `cleaned_text` contains the processed text after removal of special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efd954c8-308a-47be-9513-becf2670144f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   AashokKumar     91 0176884977  Bangalore India  https   www linkedin com in techaieashok    h  https   github com loavespacetec Profile  Passionateaboutnewtechnologyhavingexperienceof2yearsinPython DataScience MachineLearning SQL   Cloud etc IhaveworkedonvariousprojectsindifferentdomainsofAIandMLfieldtosolvechallengingbusiness  problems   ProfessionalExperience  Syste  m    Engineer      TC  S  Oct2021 present     Bangalore   India     Crastrategiestominimizerisksindecision makingandenhanceprofitabilitythroughtheuseofdatascience     Workingwithinanagileenvironment Ihaveeffectivelymanagedmultipletasksandprioritieswhilecollaborating    withcross functionalteamstodeliverprojectsontimeandtoahighstandard Ihaveparticipatedindailystand   upcallsandworkedwithinsprintcyclestoensurethetimelydeliveryofkeydeliverables      Mystronganalyticalskills combinedwithmyabilitytocommunicatecomplexfindingsinaclearandconcise    manner haveallowedmetoeffectivelycontributetodecision makingprocessesanddrivepositivebusiness    outcomes Iamhighlymotivatedandtakeprideindeliveringhigh qualityworkthatmeetstheneedsof    stakeholdersandexceedsexpectations      Performedexploratorydataanalysisforthecustomerdataaercleaningtherawdata toderivemeaningful    insightsandoutcomes      Buildpredictivemodelsusingdifferentmachinelearningalgorithmstopredicttheprobabilityofcustomeron   timeloanrepayment IhavealsoutilizedTableautocreatecompellingvisualizationstosupportmyfindingsand    insights      Evaluatedtheaccuracyofthemodelsthroughtheuseofmetricssuchastheclassificationreport confusion    matrix AUCscore etc      UtilizedvariousPythonlibrariesincludingNumPy Pandas Matplotlib Seaborn Scikit learn PySpark andSciPy    toeffectivelyperformdataanalysisandmodeling      AppliedvarioustoolssuchasTableau JupyterNotebook TensorFlow Anaconda Git Jira Confluence and    Dockerindataanalysisandmodelingprocessestoincreaseefficiencyandeffectiveness   Assistan  t   Syste  m       Engineer   S  TC Mar2021 Sep2021     Bangalore   India     Involvedintheanalysisoftestcases writingoffeaturefilesusingtheGherkinlanguageabusinessdecipherable    language andimplementationusingC forautomationtesting      UsedUFTDeveloperforcapturingobjectsduringautomationtestinganddevelopment      UtilizedvarioustoolssuchasVisualStudio UFTDeveloper Jira Confluence etctoperformautomation      ReceivedtheLearningAchievementAwardinrecognitionofmydedicationandachievementsinprofessional     development     Successfullypassedtheinternalassessmentandreceivedadigitalprofile leadingtoapromotiontotheposition     of System Engineer  PersonalProjects  Predictio  n    f  o   custome  r   eligibilit  y   fo  r    credi  t   usin  g    Machin  e    Learnin  g     WorkedwithalargedatasetofTaiwancustomerstopredictthelikelihoodofdefaultpaymentsandsupport    informeddecision making    \\naashokrekumar@gmail.com'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = clean_resume_text(resume_text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd1027-9eed-4414-b1ff-3cf57115b759",
   "metadata": {},
   "source": [
    "#### 3. The information about the candidate in the structured format is stored in `resume_info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d5e37d-af0d-4005-87f5-01db137a60c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is the extracted information in dictionary format:\\n\\n```\\n{\\n    'name': 'Aashok Kumar',\\n    'email': 'aashokrekumar@gmail.com',\\n    'technical_skills': ['Python', 'Data Science', 'Machine Learning', 'SQL', 'Cloud', 'NumPy', 'Pandas', 'Matplotlib', 'Seaborn', 'Scikit learn', 'PySpark', 'SciPy', 'Tableau', 'Jupyter Notebook', 'TensorFlow', 'Anaconda', 'Git', 'Jira', 'Confluence', 'Docker', 'C', 'UFT Developer', 'Visual Studio'],\\n    'soft_skills': ['Passionate', 'Strong analytical skills', 'Ability to communicate complex findings', 'Highly motivated', 'Effective collaboration', 'Time management', 'Prioritization', 'Decision making', 'Problem solving', 'Communication', 'Teamwork'],\\n    'projects': ['Prediction of customer eligibility for credit using Machine Learning'],\\n    'work_experience': ['System Engineer at TC S', 'Assistant System Engineer at TC S'],\\n    'total_years_of_experience': '1 year 9 months'\\n}\\n```\\n\\nNote: The total years of experience is calculated based on the provided information, which is from March 2021 to present, which is approximately 1 year and 9 months.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_info = extract_resume_info_from_text(cleaned_text)\n",
    "resume_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c94ed9-154c-4ad2-b493-0d1b8f5aae62",
   "metadata": {},
   "source": [
    "#### 4. `store_to_csv` function finally stores the candidate information in the Excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f1411bd-0ec8-4cee-8245-d2bec51d6710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored successfully in sample_resume.csv.\n"
     ]
    }
   ],
   "source": [
    "store_to_csv(resume_info, 'sample_resume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca25b44-400b-48f7-a413-c712ec4aa631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>technical_skills</th>\n",
       "      <th>soft_skills</th>\n",
       "      <th>projects</th>\n",
       "      <th>work_experience</th>\n",
       "      <th>total_years_of_experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aashok Kumar</td>\n",
       "      <td>aashokrekumar@gmail.com</td>\n",
       "      <td>['Python', 'Data Science', 'Machine Learning',...</td>\n",
       "      <td>['Passionate', 'Strong analytical skills', 'Ab...</td>\n",
       "      <td>['Prediction of customer eligibility for credi...</td>\n",
       "      <td>['System Engineer at TC S', 'Assistant System ...</td>\n",
       "      <td>1 year 9 months</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name                    email  \\\n",
       "0  Aashok Kumar  aashokrekumar@gmail.com   \n",
       "\n",
       "                                    technical_skills  \\\n",
       "0  ['Python', 'Data Science', 'Machine Learning',...   \n",
       "\n",
       "                                         soft_skills  \\\n",
       "0  ['Passionate', 'Strong analytical skills', 'Ab...   \n",
       "\n",
       "                                            projects  \\\n",
       "0  ['Prediction of customer eligibility for credi...   \n",
       "\n",
       "                                     work_experience total_years_of_experience  \n",
       "0  ['System Engineer at TC S', 'Assistant System ...           1 year 9 months  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('sample_resume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b774d-97e7-4f32-a3d7-ae1fd3e4e3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
